import os
import time
import json
import paho.mqtt.client as paho
import streamlit as st
from PIL import Image
from bokeh.models.widgets import Button
from bokeh.models import CustomJS
from streamlit_bokeh_events import streamlit_bokeh_events

# --- CONFIGURACI√ìN MQTT ---
BROKER = "broker.mqttdashboard.com"
PORT = 1883
CLIENT_ID = "CONTROL-VOZ-MQTT"

message_received = ""

def on_publish(client, userdata, result):
    print("‚úÖ Mensaje MQTT enviado.")

def on_message(client, userdata, message):
    global message_received
    message_received = str(message.payload.decode("utf-8"))
    st.success(f"üì© MQTT dice: {message_received}")

client = paho.Client(CLIENT_ID)
client.on_message = on_message

# --- INTERFAZ STREAMLIT ---
st.set_page_config(page_title="Acceso Inteligente por Voz", layout="centered")
st.markdown("""
    <style>
    .big-title {
        font-size: 40px;
        font-weight: bold;
        text-align: center;
        color: #2E86C1;
        margin-bottom: 10px;
    }
    .section-title {
        font-size: 22px;
        margin-top: 30px;
        color: #154360;
        font-weight: bold;
    }
    .instructions {
        font-size: 16px;
        color: #424949;
    }
    </style>
""", unsafe_allow_html=True)

st.markdown('<p class="big-title">üîí Acceso Inteligente por Reconocimiento de Voz</p>', unsafe_allow_html=True)

# Imagen decorativa
st.image("voice_ctrl.jpg", width=280, caption="Sistema de Seguridad Activado")

# Expansor para instrucciones
with st.expander("‚ÑπÔ∏è C√≥mo usar el sistema de acceso"):
    st.markdown("""
    <div class="instructions">
    1. Presiona el bot√≥n <b>Iniciar Reconocimiento de Voz</b>.<br>
    2. Pronuncia la palabra clave: <code>casa</code>.<br>
    3. Si el sistema detecta la palabra clave, <b>desbloquear√° la puerta</b>.<br>
    4. Si dices otra palabra, el acceso ser√° denegado.<br>
    5. El sistema env√≠a el resultado a trav√©s de MQTT.
    </div>
    """, unsafe_allow_html=True)

# Bot√≥n Bokeh personalizado
st.markdown('<p class="section-title">üé§ Activar Reconocimiento de Voz</p>', unsafe_allow_html=True)

stt_button = Button(label="üéôÔ∏è Iniciar Reconocimiento de Voz", width=320)
stt_button.js_on_event("button_click", CustomJS(code="""
    var recognition = new webkitSpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;

    recognition.onresult = function (e) {
        var value = "";
        for (var i = e.resultIndex; i < e.results.length; ++i) {
            if (e.results[i].isFinal) {
                value += e.results[i][0].transcript;
            }
        }
        if (value !== "") {
            document.dispatchEvent(new CustomEvent("GET_TEXT", { detail: value }));
        }
    };
    recognition.start();
"""))

# Captura del evento
result = streamlit_bokeh_events(
    stt_button,
    events="GET_TEXT",
    key="listener",
    refresh_on_update=False,
    override_height=100,
    debounce_time=0
)

# Resultado del reconocimiento
if result and "GET_TEXT" in result:
    command = result.get("GET_TEXT").strip().lower()
    
    st.markdown('<p class="section-title">üìù Palabra detectada:</p>', unsafe_allow_html=True)
    st.code(command, language='markdown')

    client.on_publish = on_publish
    client.connect(BROKER, PORT)

    if command in ["casa", "casa."]:
        st.success("üîì Acceso concedido: Puerta desbloqueada")
        msg = json.dumps({"codigo": "casa"})
    else:
        st.error("‚õî Acceso denegado: C√≥digo incorrecto")
        msg = json.dumps({"codigo": "incorrecto"})

    client.publish("nicolas_ctrl", msg)

    os.makedirs("temp", exist_ok=True)
